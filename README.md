# Predicci√≥n de Ingresos con Adult UCI Dataset
## Proyecto Final - Modelos y Simulaci√≥n II

**Autores:**
- Dayana Ramirez
- Wilmar Osorio
- Santiago Arenas

## üé¨ Video del proyecto  
[Modelos II ‚Äì Proyecto Final (Exposici√≥n)](https://drive.google.com/file/d/1N6FNI8GnlcS0rr_gmx_B-G-k25JGHXKQ/view?usp=drive_link)

Este repositorio contiene la soluci√≥n completa para el proyecto final del curso *Modelos y Simulaci√≥n II*. El objetivo principal es desarrollar, comparar y optimizar modelos de Machine Learning para predecir si una persona tiene ingresos superiores a $50K anuales, bas√°ndose en caracter√≠sticas demogr√°ficas y laborales del dataset Adult UCI.

## üìã Descripci√≥n del Proyecto

El proyecto aborda un problema de **clasificaci√≥n binaria desbalanceada** utilizando el dataset est√°ndar Adult UCI (32,561 muestras, 14 caracter√≠sticas). La soluci√≥n implementada sigue estrictamente los lineamientos de la gu√≠a del curso y cubre las siguientes secciones:

### Secci√≥n 0-3: Preparaci√≥n y An√°lisis Exploratorio
- **Carga del Dataset**: Descarga autom√°tica desde repositorio UCI
- **Limpieza de Datos**: Manejo de valores faltantes (imputaci√≥n por moda)
- **Codificaci√≥n**: One-Hot Encoding para variables categ√≥ricas (108 caracter√≠sticas resultantes)
- **Normalizaci√≥n**: StandardScaler aplicado dentro de pipelines CV
- **Manejo de Desbalance**: SMOTE integrado en pipelines para evitar data leakage

### Secci√≥n 4: Entrenamiento y Evaluaci√≥n de Modelos
Implementaci√≥n completa de **5 familias de modelos de Machine Learning**:

1. **Regresi√≥n Log√≠stica** (Modelo Param√©trico)
   - Hiperpar√°metros: C ‚àà {0.01, 0.1, 1, 10}, penalty ‚àà {l1, l2}, solver=saga
   - Optimizaci√≥n: GridSearchCV con 5-fold StratifiedKFold
   
2. **K-Vecinos m√°s Cercanos** (Modelo No Param√©trico)
   - Hiperpar√°metros: n_neighbors ‚àà {3, 5, 7, 9, 11}, weights ‚àà {uniform, distance}
   - Optimizaci√≥n: GridSearchCV con 5-fold StratifiedKFold
   
3. **Random Forest** (Modelo de Ensamble)
   - Hiperpar√°metros: n_estimators ‚àà {100, 200}, max_depth ‚àà {10, 20, None}, min_samples_split ‚àà {2, 5}
   - Optimizaci√≥n: RandomizedSearchCV (20 iteraciones)
   
4. **Red Neuronal MLP** (Perceptr√≥n Multicapa)
   - Hiperpar√°metros: hidden_layer_sizes ‚àà {(50,), (100,), (50,50)}, activation ‚àà {relu, tanh}, alpha ‚àà {0.0001, 0.001}
   - Optimizaci√≥n: RandomizedSearchCV (20 iteraciones)
   
5. **SVM con Kernel RBF** (M√°quinas de Vectores de Soporte)
   - Hiperpar√°metros: C ‚àà {0.1, 1, 10}, gamma ‚àà {0.01, 0.1, 1}
   - **Optimizaci√≥n Especial**: Uso de 40% del dataset con 3-fold CV para reducir tiempo de entrenamiento (2+ horas ‚Üí 15-20 minutos)

**M√©tricas de Evaluaci√≥n:**
- F1-Score (m√©trica principal para datos desbalanceados)
- ROC-AUC (√°rea bajo la curva ROC)
- Precision y Recall
- Intervalos de Confianza del 95% calculados con desviaci√≥n est√°ndar de CV
- Visualizaciones: Curvas ROC, Matrices de Confusi√≥n, Gr√°ficos comparativos

### Secci√≥n 4.1: Tabla de Hiperpar√°metros
Documentaci√≥n completa de todos los grids de b√∫squeda utilizados para cada modelo, incluyendo espacios de b√∫squeda y estrategias de optimizaci√≥n.

### Secci√≥n 5: Reducci√≥n de Dimensionalidad

**5.1. An√°lisis de Importancia de Variables**
- **Mutual Information**: Medida de dependencia entre caracter√≠sticas y variable objetivo
- **Chi-Cuadrado (œá¬≤)**: Prueba estad√≠stica para variables categ√≥ricas
- **ANOVA F-value**: An√°lisis de varianza para caracter√≠sticas continuas
- Identificaci√≥n de caracter√≠sticas de baja relevancia (< percentil 25)
- Visualizaciones: Top 20 mejores, Bottom 20 peores, distribuciones, comparaci√≥n entre m√©todos

**5.2. PCA (Reducci√≥n Dimensional Lineal)**
- An√°lisis de varianza explicada acumulada
- Selecci√≥n autom√°tica de componentes (95% de varianza conservada)
- Re-entrenamiento de los 2 mejores modelos con datos transformados
- Comparaci√≥n de rendimiento: Original vs PCA
- Reducci√≥n dimensional lograda: ~50-60% menos dimensiones

**5.3. UMAP (Reducci√≥n Dimensional No Lineal)**
- Proyecci√≥n a espacio de 20 componentes
- Par√°metros: n_neighbors=15, min_dist=0.1, metric='euclidean'
- Re-entrenamiento de los 2 mejores modelos con datos transformados
- Comparaci√≥n de rendimiento: Original vs UMAP
- Capacidad de capturar relaciones no lineales complejas

**5.4. Comparaci√≥n Global**
- Tabla resumen: Original vs PCA vs UMAP
- Visualizaciones comparativas de F1-Score y ROC-AUC
- An√°lisis de porcentaje de reducci√≥n dimensional
- Recomendaciones autom√°ticas seg√∫n rendimiento

**Conclusiones de la Secci√≥n 5:**
- Identificaci√≥n de las variables m√°s relevantes para predicci√≥n de ingresos
- PCA ofrece interpretabilidad y reducci√≥n significativa manteniendo rendimiento
- UMAP captura relaciones no lineales y puede mejorar rendimiento en algunos casos
- Trade-off entre dimensionalidad, interpretabilidad y rendimiento

## üõ† Tecnolog√≠as y Dependencias

El proyecto est√° desarrollado en **Python 3.8+** y utiliza las siguientes bibliotecas:

| Biblioteca | Versi√≥n | Prop√≥sito |
|------------|---------|-----------|
| `pandas` | ‚â•1.3.0 | Manipulaci√≥n y an√°lisis de datos |
| `numpy` | ‚â•1.21.0 | Operaciones num√©ricas y √°lgebra lineal |
| `scikit-learn` | ‚â•1.0.0 | Modelos de ML, m√©tricas, preprocesamiento |
| `imbalanced-learn` | ‚â•0.9.0 | T√©cnicas de balanceo (SMOTE) |
| `matplotlib` | ‚â•3.4.0 | Visualizaciones est√°ticas |
| `seaborn` | ‚â•0.11.0 | Visualizaciones estad√≠sticas mejoradas |
| `scipy` | ‚â•1.7.0 | Funciones cient√≠ficas y estad√≠sticas |
| `joblib` | ‚â•1.1.0 | Persistencia de modelos |
| `umap-learn` | ‚â•0.5.0 | Reducci√≥n dimensional no lineal |

### Instalaci√≥n Autom√°tica

El notebook incluye una **celda de configuraci√≥n inicial** que instala todas las dependencias autom√°ticamente:

```python
# Celda 0 del notebook - Instalaci√≥n autom√°tica
import subprocess
import sys

packages = [
    'pandas', 'numpy', 'scikit-learn', 
    'imbalanced-learn', 'matplotlib', 
    'seaborn', 'scipy', 'joblib', 'umap-learn'
]

for package in packages:
    subprocess.check_call([sys.executable, "-m", "pip", "install", package])
```

**No es necesario instalar manualmente** las dependencias si ejecutas el notebook completo desde el inicio.

## üöÄ Gu√≠a de Uso

### 1. Clonar el Repositorio
```bash
git clone https://github.com/wil101/Proyecto_Final_Modelos_II.git
cd Proyecto_Final_Modelos_II
```

### 2. Ejecutar el Notebook
Abre el archivo `entrenamiento_evaluacion_modelos.ipynb` en:
- **Jupyter Notebook**: `jupyter notebook`
- **Jupyter Lab**: `jupyter lab`
- **VS Code**: Con extensi√≥n de Python y Jupyter
- **Google Colab**: Subir el archivo directamente

### 3. Ejecuci√≥n Secuencial
El notebook est√° dise√±ado para ejecutarse **de principio a fin**:

1. **Celda 0**: Instalaci√≥n autom√°tica de dependencias (2-3 minutos)
2. **Celdas 1-10**: Carga y preprocesamiento del dataset (1-2 minutos)
3. **Celdas 11-45**: Entrenamiento de 5 modelos con optimizaci√≥n de hiperpar√°metros
   - Logistic Regression: ~2-3 minutos
   - k-NN: ~3-4 minutos
   - Random Forest: ~5-7 minutos
   - MLP Neural Network: ~8-10 minutos
   - SVM (optimizado): ~15-20 minutos
4. **Celdas 46-50**: Visualizaciones y comparaciones de rendimiento
5. **Celda 51**: Tabla de hiperpar√°metros (Secci√≥n 4.1)
6. **Celdas 52-60**: An√°lisis de reducci√≥n dimensional (Secci√≥n 5)

**Tiempo total estimado**: 40-50 minutos

### 4. Descarga Autom√°tica del Dataset
El notebook descarga el dataset directamente desde el repositorio UCI:
```python
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'
```
**No es necesario descargar archivos CSV manualmente**.

### 5. Resultados Generados
Al finalizar la ejecuci√≥n, obtendr√°s:
- ‚úÖ M√©tricas de rendimiento de 5 modelos con intervalos de confianza
- ‚úÖ Visualizaciones: Curvas ROC, matrices de confusi√≥n, gr√°ficos comparativos
- ‚úÖ Tabla de hiperpar√°metros √≥ptimos encontrados
- ‚úÖ An√°lisis de importancia de variables
- ‚úÖ Comparaci√≥n de t√©cnicas de reducci√≥n dimensional (PCA vs UMAP)
- ‚úÖ Recomendaciones basadas en resultados experimentales

## üìä Estructura del Notebook

El notebook `entrenamiento_evaluacion_modelos.ipynb` sigue la estructura oficial de la gu√≠a del proyecto:

| Secci√≥n | Descripci√≥n | Celdas Aprox. |
|---------|-------------|---------------|
| **0** | Instalaci√≥n de dependencias | 1 |
| **1-3** | Carga, exploraci√≥n y preprocesamiento del dataset | 10 |
| **4** | Entrenamiento y evaluaci√≥n de 5 modelos de ML | 35 |
| **4.1** | Tabla de hiperpar√°metros y configuraci√≥n experimental | 1 |
| **5.1** | An√°lisis de importancia de variables | 2 |
| **5.2** | PCA: Reducci√≥n dimensional lineal | 3 |
| **5.3** | UMAP: Reducci√≥n dimensional no lineal | 3 |
| **5.4** | Comparaci√≥n global de t√©cnicas | 2 |
| **Conclusiones** | Resumen y recomendaciones finales | 1 |

**Total**: ~60 celdas organizadas secuencialmente

### Visualizaciones Incluidas
- üìà Curvas ROC de los 5 modelos
- üî¢ Matrices de confusi√≥n para cada modelo
- üìä Gr√°ficos de barras comparando m√©tricas (F1, ROC-AUC, Precision, Recall)
- üéØ Importancia de variables (Top 20, Bottom 20, distribuciones)
- üìâ Varianza explicada acumulada en PCA
- üîÑ Comparaci√≥n visual Original vs PCA vs UMAP

## üìÅ Estructura del Repositorio

```
Proyecto_Final_Modelos_II/
‚îÇ
‚îú‚îÄ‚îÄ entrenamiento_evaluacion_modelos.ipynb    # Notebook principal con todo el an√°lisis
‚îú‚îÄ‚îÄ README.md                                 # Este archivo
‚îú‚îÄ‚îÄ .gitignore                                # Archivos excluidos de control de versiones
‚îî‚îÄ‚îÄ archivos/                                 # Directorio de recursos (vac√≠o inicialmente)
```

### Archivos Excluidos (.gitignore)
Para mantener el repositorio ligero y evitar problemas con l√≠mites de tama√±o de GitHub:
- `modelos_entrenados/` - Modelos serializados (.pkl, .joblib)
- `*.pkl` - Archivos pickle de modelos
- `__pycache__/` - Cache de Python
- `.ipynb_checkpoints/` - Checkpoints de Jupyter

**Nota**: Los modelos entrenados NO est√°n incluidos en el repositorio. Se generan autom√°ticamente al ejecutar el notebook.

## üî¨ Metodolog√≠a Experimental

### Validaci√≥n Cruzada Estratificada
- **Estrategia**: StratifiedKFold (k=5 para la mayor√≠a de modelos, k=3 para SVM optimizado)
- **Prop√≥sito**: Mantener la proporci√≥n de clases en cada fold
- **Beneficio**: Evita sesgo en datasets desbalanceados

### Prevenci√≥n de Data Leakage
- **Pipeline Integration**: SMOTE y StandardScaler se aplican SOLO en datos de entrenamiento
- **Uso de `ImbPipeline`**: De la biblioteca `imbalanced-learn`
- **Orden del Pipeline**: StandardScaler ‚Üí SMOTE ‚Üí Classifier

### Optimizaci√≥n de Hiperpar√°metros
| Modelo | M√©todo | Iteraciones | Tiempo Aprox. |
|--------|--------|-------------|---------------|
| Logistic Regression | GridSearchCV | 16 combinaciones | 2-3 min |
| k-NN | GridSearchCV | 10 combinaciones | 3-4 min |
| Random Forest | RandomizedSearchCV | 20 muestras | 5-7 min |
| MLP | RandomizedSearchCV | 20 muestras | 8-10 min |
| SVM | RandomizedSearchCV | 6 muestras (40% datos) | 15-20 min |

### C√°lculo de Intervalos de Confianza
```
IC 95% = Œº ¬± 1.96 √ó (œÉ / ‚àök)
```
Donde:
- Œº = media de la m√©trica en k folds
- œÉ = desviaci√≥n est√°ndar
- k = n√∫mero de folds (5 o 3)

## üéØ Resultados Esperados

Al ejecutar el notebook completo, se obtienen m√©tricas de rendimiento para:

### Modelos Baseline (Datos Originales)
- 5 modelos entrenados con 108 caracter√≠sticas
- M√©tricas con intervalos de confianza del 95%
- Identificaci√≥n de los 2 mejores modelos

### Reducci√≥n Dimensional
- **PCA**: ~50-60% reducci√≥n manteniendo 95% de varianza
- **UMAP**: Proyecci√≥n a 20 componentes capturando relaciones no lineales
- Comparaci√≥n de rendimiento en ambos espacios reducidos

### Comparaci√≥n Final
Tabla comparativa mostrando:
- F1-Score Original vs PCA vs UMAP
- ROC-AUC Original vs PCA vs UMAP
- Porcentaje de reducci√≥n dimensional
- Recomendaci√≥n autom√°tica del mejor enfoque

## üí° Aspectos T√©cnicos Destacados

### 1. Optimizaci√≥n del SVM
El modelo SVM con kernel RBF es computacionalmente costoso. Para hacerlo viable:
- **Estrategia de Muestreo**: Se utiliza 40% del dataset manteniendo estratificaci√≥n
- **Reducci√≥n de CV**: 3-fold en lugar de 5-fold
- **Grid Reducido**: 3√ó3√ó1 = 9 combinaciones, 6 iteraciones totales
- **Cache**: `cache_size=1000` MB para acelerar c√°lculos
- **Resultado**: Reducci√≥n de 2+ horas a 15-20 minutos sin sacrificar validez

### 2. Manejo de Desbalance
- **Clase Mayoritaria**: ‚â§50K (~76%)
- **Clase Minoritaria**: >50K (~24%)
- **T√©cnica**: SMOTE (Synthetic Minority Over-sampling Technique)
- **Implementaci√≥n**: Dentro del pipeline de CV para evitar contaminaci√≥n
- **Beneficio**: Mejora recall y F1-score significativamente

### 3. Reproducibilidad
- **Random Seeds**: Fijados en todas las operaciones aleatorias
- **Instalaci√≥n Autom√°tica**: No requiere configuraci√≥n manual del entorno

## üìö Referencias

- **Dataset**: [UCI Machine Learning Repository - Adult Data Set](https://archive.ics.uci.edu/ml/datasets/adult)
- **SMOTE**: Chawla, N. V., et al. (2002). "SMOTE: Synthetic Minority Over-sampling Technique"
- **PCA**: Jolliffe, I. T. (2002). "Principal Component Analysis"
- **UMAP**: McInnes, L., et al. (2018). "UMAP: Uniform Manifold Approximation and Projection"
- **Scikit-learn**: Pedregosa, F., et al. (2011). "Scikit-learn: Machine Learning in Python"


